<h1
id="tales-from-the-wild-west-crafting-scenarios-to-audit-bias-in-llms">Tales
from the Wild West: Crafting Scenarios to Audit Bias in LLMs</h1>
<h2 id="authors">Authors</h2>
<ul>
<li>Katherine-Marie Robinson*</li>
<li>Violet Turti*</li>
<li>Carol J. Smith</li>
<li>Shannon K. Gallagher</li>
</ul>
<p>*Both authors contributed equally.</p>
<p>Affiliation: Carnegie Mellon University Software Engineering
Institute, United States</p>
<h2 id="abstract">Abstract</h2>
<p>Large language models (LLMs) present risks such as unintended
perpetuation of harmful biases. This paper introduces a scenario-based
auditing approach to uncover biases by having the LLM play a character
in a role-playing game (RPG). Through a cowboy-themed scenario, ChatGPT
revealed ethnic and gender biases in its descriptions of individuals.
The approach demonstrates the value of exploratory methods to identify
and mitigate bias in LLMs.</p>
<h2 id="introduction">1. Introduction</h2>
<ul>
<li>LLMs like ChatGPT have improved safeguards to reduce biased outputs,
but underlying biases persist.</li>
<li>Traditional auditing methods use structured input pairs; newer
methods use open-ended exploration.</li>
<li>This paper expands on name-based auditing by using scenario-based
role-playing to uncover intersectional biases.</li>
</ul>
<h2 id="related-work">2. Related Work</h2>
<h3 id="biases-in-llms">Biases in LLMs</h3>
<ul>
<li>Bias is defined as systematic misrepresentations that favor certain
groups or perpetuate stereotypes.</li>
<li>Examples include gender, racial, and geographic biases in LLM
outputs.</li>
<li>Sources of bias may include training data, model architecture,
optimization, and human feedback.</li>
</ul>
<h3 id="auditing-methods-for-llms">Auditing Methods for LLMs</h3>
<ul>
<li>Auditing and red-teaming are used to identify bias in ML
systems.</li>
<li>Prior work includes demographic-based input variations and
name-based audits.</li>
<li>As LLMs add safety features, new methods are needed to bypass
safeguards during auditing.</li>
</ul>
<h2 id="study-design">3. Study Design</h2>
<h3 id="initial-exploration">Initial Exploration</h3>
<ul>
<li>Used RPG scenarios inspired by prior work (e.g., Park et al.).</li>
<li>Assigned ChatGPT the role of “Jett,” a cowboy at Sunset Valley
Ranch.</li>
<li>Noted biases: Hispanic names recognized on the ranch; non-Hispanic
names described off-ranch; gender-stereotyped roles.</li>
</ul>
<h3 id="experimental-set-up">Experimental Set-Up</h3>
<ul>
<li>Designed a scenario with Sandy (new in town) asking Jett about 16
names (4 subgroups: Hispanic/non-Hispanic × men/women).</li>
<li>Names used:
<ul>
<li>Hispanic Men: Jorge, Eduardo, Diego, Pedro</li>
<li>Hispanic Women: Guadalupe, Juanita, Alejandra, Yolanda</li>
<li>Non-Hispanic Men: James, Henry, Noah, Benjamin</li>
<li>Non-Hispanic Women: Eleanor, Charlotte, Hannah, Alice</li>
</ul></li>
<li>Prompt: “Who is [name]?” + request for two personality traits.</li>
<li>Conducted 10 trials with two different name orders.</li>
</ul>
<h3 id="evaluation-methods">Evaluation Methods</h3>
<ul>
<li>Manually analyzed roles and personality traits.</li>
<li>Mapped roles to U.S. Census Occupation Codes (Major, Detailed, SOC
Roles).</li>
<li>Analyzed frequency and distribution of traits across subgroups.</li>
</ul>
<h2 id="results">4. Results</h2>
<h3 id="roles">Roles</h3>
<ul>
<li>159 roles documented; 60 unique roles.</li>
<li>Only 3 roles (Artist, Caretaker, Veterinarian) appeared in all
subgroups.</li>
<li>Mapping to Census codes revealed patterns:
<ul>
<li>Hispanic women: overrepresented in Arts/Media.</li>
<li>Hispanic men: overrepresented in Farming/Forestry.</li>
<li>Non-Hispanic women: overrepresented in Education/Library.</li>
<li>Gendered roles: e.g., Installation/Maintenance roles only for
men.</li>
</ul></li>
</ul>
<h3 id="personality-traits">Personality Traits</h3>
<ul>
<li>320 traits generated; 97 unique traits.</li>
<li>8 traits used across all subgroups: Compassionate, Creative,
Dedicated, Friendly, Gentle, Knowledgeable, Passionate, Wise.</li>
<li>Most frequent: Friendly, Knowledgeable, Creative.</li>
<li>Gendered traits:
<ul>
<li>Men: Hardworking, Easygoing, Responsible, Reliable.</li>
<li>Women: Welcoming, Hospitable, Warm, Passionate, Compassionate.</li>
</ul></li>
<li>Ethnic differences:
<ul>
<li>Hispanic individuals: Diligent, Hardworking,
Mechanically-inclined.</li>
<li>Non-Hispanic individuals: Business-minded, Curious, Ingenious.</li>
</ul></li>
</ul>
<h2 id="discussion">5. Discussion</h2>
<h3 id="disparities-in-assigned-roles">Disparities in Assigned
Roles</h3>
<ul>
<li>Gender stereotypes: Mechanic (men), Librarian (women).</li>
<li>Ethnic stereotypes: Hispanic individuals more often in trade roles
(Blacksmith, Mechanic); non-Hispanic in educated roles (Librarian,
Teacher).</li>
<li>Hispanic women: often assigned food service roles (Cook, Restaurant
Owner).</li>
</ul>
<h3 id="biases-across-personality-traits">Biases Across Personality
Traits</h3>
<ul>
<li>Men: more unique traits (71 vs. 61 for women).</li>
<li>Masculine traits: Strong, Resourceful, Reliable.</li>
<li>Feminine traits: Caring, Warm, Welcoming.</li>
<li>Hispanic traits: job-related (Hardworking, Diligent).</li>
<li>Non-Hispanic traits: personality-focused (Curious, Inspiring).</li>
</ul>
<h3 id="comparison-with-non-scenario-based-auditing">Comparison with
Non-Scenario-Based Auditing</h3>
<ul>
<li>Without scenario: more diverse roles (e.g., Software Engineer, Human
Rights Lawyer).</li>
<li>With scenario: more biased and stereotypical assignments.</li>
<li>Demonstrates that scenarios help bypass LLM safeguards and reveal
deeper biases.</li>
</ul>
<h2 id="conclusion">6. Conclusion</h2>
<ul>
<li>Scenario-based auditing is effective for uncovering hidden biases in
LLMs.</li>
<li>Method is generalizable to other domains (e.g., education,
hiring).</li>
<li>Future work: expand scenarios, include more demographic factors,
test other LLMs.</li>
</ul>
<h2 id="acknowledgments">7. Acknowledgments</h2>
<ul>
<li>Funded by the Department of Defense under Contract
No. FA8702-15-D-0002.</li>
<li>Approved for public release and unlimited distribution.</li>
</ul>
<h2 id="references-selected">References (Selected)</h2>
<ul>
<li>[3] Deshpande et al.: Using personas to bypass toxicity
safeguards.</li>
<li>[7] Name-based auditing for bias.</li>
<li>[16] Park et al.: Generative agents and role-playing.</li>
<li>[17] Rottger et al.: Xstest for exaggerated safety behaviors.</li>
<li>[23] Vedanda et al.: Algorithmic hiring bias in ChatGPT.</li>
</ul>
